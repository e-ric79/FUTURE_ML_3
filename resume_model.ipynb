{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRjimNOOPI_e"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploads=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"Resume.csv\")\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nColumns:\")\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "LCBh1LnnxEak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"RESUME DATASET EXPLORATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nTotal resumes: {len(df):,}\")\n",
        "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
        "\n",
        "# Check categories (job roles)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RESUME CATEGORIES (Job Roles)\")\n",
        "print(\"=\"*70)\n",
        "print(df['Category'].value_counts())\n",
        "\n",
        "print(f\"\\nTotal categories: {df['Category'].nunique()}\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(12, 6))\n",
        "df['Category'].value_counts().plot(kind='bar', color='skyblue')\n",
        "plt.title('Resume Distribution by Job Category')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Number of Resumes')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Sample resume text\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAMPLE RESUME\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nCategory: {df['Category'].iloc[0]}\")\n",
        "print(f\"\\nResume Text (first 300 chars):\")\n",
        "print(df['Resume_str'].iloc[0][:300])\n",
        "\n",
        "print(f\"\\n\\nAnother sample - Category: {df['Category'].iloc[10]}\")\n",
        "print(f\"\\nResume Text (first 300 chars):\")\n",
        "print(df['Resume_str'].iloc[10][:300])"
      ],
      "metadata": {
        "id": "pAtRwIgSim0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4 -q\n",
        "\n",
        "import re\n",
        "import string\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STEP 2: TEXT PREPROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Function to clean resume text\n",
        "def clean_resume_text(text):\n",
        "    # Remove HTML tags (some resumes have HTML)\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "\n",
        "    # Remove email addresses\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "\n",
        "    # Remove special characters and digits (keep letters and spaces)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply cleaning to all resumes\n",
        "print(\"\\nCleaning resumes...\")\n",
        "df['Resume_clean'] = df['Resume_str'].apply(clean_resume_text)\n",
        "\n",
        "print(\"âœ“ Cleaning complete!\")\n",
        "\n",
        "# Show before/after examples\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BEFORE/AFTER CLEANING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n--- Example 1 ---\")\n",
        "print(f\"Category: {df['Category'].iloc[0]}\")\n",
        "print(f\"\\nBEFORE (first 200 chars):\")\n",
        "print(df['Resume_str'].iloc[0][:200])\n",
        "print(f\"\\nAFTER (first 200 chars):\")\n",
        "print(df['Resume_clean'].iloc[0][:200])\n",
        "\n",
        "print(\"\\n--- Example 2 ---\")\n",
        "print(f\"Category: {df['Category'].iloc[50]}\")\n",
        "print(f\"\\nBEFORE (first 200 chars):\")\n",
        "print(df['Resume_str'].iloc[50][:200])\n",
        "print(f\"\\nAFTER (first 200 chars):\")\n",
        "print(df['Resume_clean'].iloc[50][:200])\n",
        "\n",
        "# Check text length distribution\n",
        "df['text_length'] = df['Resume_clean'].str.len()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEXT LENGTH STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(df['text_length'].describe())\n",
        "\n",
        "print(f\"\\nâœ“ Step 2 Complete: {len(df):,} resumes preprocessed\")"
      ],
      "metadata": {
        "id": "Iwn_qzSNjcrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"STEP 3: SKILL EXTRACTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Define skill keywords to extract\n",
        "\n",
        "SKILLS_DATABASE = {\n",
        "    'Programming': [\n",
        "        'python', 'java', 'javascript', 'c++', 'c#', 'ruby', 'php', 'swift',\n",
        "        'kotlin', 'r', 'sql', 'html', 'css', 'typescript', 'go', 'rust'\n",
        "    ],\n",
        "    'Data Science & ML': [\n",
        "        'machine learning', 'deep learning', 'data science', 'data analysis',\n",
        "        'artificial intelligence', 'neural networks', 'nlp', 'computer vision',\n",
        "        'data mining', 'predictive modeling', 'statistical analysis'\n",
        "    ],\n",
        "    'Tools & Frameworks': [\n",
        "        'tensorflow', 'pytorch', 'keras', 'scikit-learn', 'pandas', 'numpy',\n",
        "        'matplotlib', 'seaborn', 'tableau', 'power bi', 'excel', 'spark',\n",
        "        'hadoop', 'docker', 'kubernetes', 'git', 'aws', 'azure', 'gcp'\n",
        "    ],\n",
        "    'Databases': [\n",
        "        'mysql', 'postgresql', 'mongodb', 'oracle', 'sql server', 'redis',\n",
        "        'cassandra', 'dynamodb', 'sqlite'\n",
        "    ],\n",
        "    'Soft Skills': [\n",
        "        'leadership', 'communication', 'teamwork', 'problem solving',\n",
        "        'project management', 'analytical', 'critical thinking', 'agile',\n",
        "        'scrum', 'collaboration'\n",
        "    ],\n",
        "    'Web Development': [\n",
        "        'react', 'angular', 'vue', 'node.js', 'django', 'flask', 'spring',\n",
        "        'rest api', 'graphql', 'web development', 'frontend', 'backend'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Flatten all skills into one list\n",
        "all_skills = []\n",
        "for category, skills in SKILLS_DATABASE.items():\n",
        "    all_skills.extend(skills)\n",
        "\n",
        "def extract_skills(text):\n",
        "    \"\"\"\n",
        "    Extract skills from resume text\n",
        "    Returns: list of found skills\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "    found_skills = []\n",
        "\n",
        "    for skill in all_skills:\n",
        "        # Use word boundaries to match whole words/phrases\n",
        "        pattern = r'\\b' + re.escape(skill) + r'\\b'\n",
        "        if re.search(pattern, text_lower):\n",
        "            found_skills.append(skill)\n",
        "\n",
        "    return found_skills\n",
        "\n",
        "# Extract skills from all resumes\n",
        "print(\"\\nExtracting skills from resumes...\")\n",
        "df['extracted_skills'] = df['Resume_clean'].apply(extract_skills)\n",
        "df['num_skills'] = df['extracted_skills'].apply(len)\n",
        "\n",
        "print(\"âœ“ Skill extraction complete!\")\n",
        "\n",
        "# Statistics\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SKILL EXTRACTION STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nAverage skills per resume: {df['num_skills'].mean():.1f}\")\n",
        "print(f\"Min skills found: {df['num_skills'].min()}\")\n",
        "print(f\"Max skills found: {df['num_skills'].max()}\")\n",
        "\n",
        "print(\"\\nSkills distribution:\")\n",
        "print(df['num_skills'].describe())\n",
        "\n",
        "# Show examples\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAMPLE SKILL EXTRACTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i in [0, 10, 20]:\n",
        "    print(f\"\\n--- Resume {i+1} ---\")\n",
        "    print(f\"Category: {df['Category'].iloc[i]}\")\n",
        "    print(f\"Skills found ({len(df['extracted_skills'].iloc[i])}): {df['extracted_skills'].iloc[i][:10]}\")\n",
        "\n",
        "print(f\"\\nâœ“ Step 3 Complete: Skills extracted from {len(df):,} resumes\")"
      ],
      "metadata": {
        "id": "LHM0fpWfkd-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STEP 4: JOB MATCHING & SCORING LOGIC\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2)\n",
        ")\n",
        "\n",
        "# Fit on all resume text\n",
        "print(\"\\nVectorizing resumes...\")\n",
        "resume_vectors = vectorizer.fit_transform(df['Resume_clean'])\n",
        "print(f\"âœ“ Created vectors: {resume_vectors.shape}\")\n",
        "\n",
        "# Function to match resumes with job description\n",
        "def match_resumes_to_job(job_description, top_n=10):\n",
        "    \"\"\"\n",
        "    Match resumes to a job description\n",
        "\n",
        "    Args:\n",
        "        job_description: str - The job posting text\n",
        "        top_n: int - Number of top candidates to return\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with ranked candidates\n",
        "    \"\"\"\n",
        "    # Clean job description\n",
        "    job_clean = clean_resume_text(job_description)\n",
        "\n",
        "    # Extract required skills from job\n",
        "    job_skills = extract_skills(job_clean)\n",
        "\n",
        "    # Vectorize job description\n",
        "    job_vector = vectorizer.transform([job_clean])\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarities = cosine_similarity(job_vector, resume_vectors)[0]\n",
        "\n",
        "    # Add similarity scores to dataframe\n",
        "    results_df = df.copy()\n",
        "    results_df['match_score'] = similarities * 100  # Convert to percentage\n",
        "\n",
        "    # Calculate skill match\n",
        "    def calculate_skill_match(candidate_skills):\n",
        "        if len(job_skills) == 0:\n",
        "            return 0, [], job_skills\n",
        "        matching = [s for s in job_skills if s in candidate_skills]\n",
        "        missing = [s for s in job_skills if s not in candidate_skills]\n",
        "        match_pct = (len(matching) / len(job_skills)) * 100\n",
        "        return match_pct, matching, missing\n",
        "\n",
        "    results_df[['skill_match_pct', 'matching_skills', 'missing_skills']] = \\\n",
        "        results_df['extracted_skills'].apply(\n",
        "            lambda x: pd.Series(calculate_skill_match(x))\n",
        "        )\n",
        "\n",
        "    # Combined score (70% text similarity + 30% skill match)\n",
        "    results_df['final_score'] = (\n",
        "        0.7 * results_df['match_score'] +\n",
        "        0.3 * results_df['skill_match_pct']\n",
        "    )\n",
        "\n",
        "    # Sort by score\n",
        "    results_df = results_df.sort_values('final_score', ascending=False)\n",
        "\n",
        "    # Return top N with relevant columns\n",
        "    return results_df[[\n",
        "        'Category', 'final_score', 'match_score', 'skill_match_pct',\n",
        "        'num_skills', 'matching_skills', 'missing_skills', 'Resume_clean'\n",
        "    ]].head(top_n), job_skills\n",
        "\n",
        "print(\"\\nâœ“ Matching system ready!\")\n",
        "\n",
        "# Test with a sample job description\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEST: DATA SCIENTIST JOB\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "job_desc = \"\"\"\n",
        "Data Scientist Position\n",
        "\n",
        "We are looking for a Data Scientist with strong Python and Machine Learning skills.\n",
        "\n",
        "Requirements:\n",
        "- Python programming\n",
        "- Machine Learning experience\n",
        "- Data analysis and statistical analysis\n",
        "- SQL and databases\n",
        "- Experience with pandas, scikit-learn\n",
        "- Communication and teamwork skills\n",
        "\n",
        "Preferred:\n",
        "- Deep learning\n",
        "- TensorFlow or PyTorch\n",
        "- AWS or cloud experience\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nJob Description:\")\n",
        "print(job_desc[:200] + \"...\")\n",
        "\n",
        "print(\"\\nMatching resumes...\")\n",
        "top_candidates, required_skills = match_resumes_to_job(job_desc, top_n=10)\n",
        "\n",
        "print(f\"\\nâœ“ Found top 10 candidates!\")\n",
        "print(f\"Required skills: {required_skills}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TOP 5 CANDIDATES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for idx, row in top_candidates.head(5).iterrows():\n",
        "    print(f\"\\n--- Candidate {list(top_candidates.index).index(idx) + 1} ---\")\n",
        "    print(f\"Category: {row['Category']}\")\n",
        "    print(f\"Final Score: {row['final_score']:.2f}%\")\n",
        "    print(f\"  - Text Match: {row['match_score']:.2f}%\")\n",
        "    print(f\"  - Skill Match: {row['skill_match_pct']:.2f}%\")\n",
        "    print(f\"Matching Skills: {row['matching_skills']}\")\n",
        "    print(f\"Missing Skills: {row['missing_skills']}\")\n",
        "\n",
        "print(f\"\\nâœ“ Step 4 Complete: Matching & scoring system built\")"
      ],
      "metadata": {
        "id": "KQhtksdS6Tlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"STEP 5: CANDIDATE RANKING WITH EXPLANATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def explain_candidate_ranking(candidate_row, rank, total_required_skills):\n",
        "    \"\"\"\n",
        "    Generate human-readable explanation for non-technical users\n",
        "    \"\"\"\n",
        "    explanation = f\"\"\"\n",
        "--------------------------------------------------------------------\n",
        " CANDIDATE #{rank}\n",
        "--------------------------------------------------------------------\n",
        "\n",
        "ðŸ“‹ CATEGORY: {candidate_row['Category']}\n",
        "\n",
        "ðŸŽ¯ OVERALL FIT: {candidate_row['final_score']:.1f}% Match\n",
        "\n",
        "ðŸ“Š BREAKDOWN:\n",
        "   â€¢ Resume Relevance: {candidate_row['match_score']:.1f}%\n",
        "   â€¢ Skills Match: {candidate_row['skill_match_pct']:.1f}% ({len(candidate_row['matching_skills'])}/{total_required_skills} required skills)\n",
        "\n",
        "âœ… MATCHING SKILLS ({len(candidate_row['matching_skills'])}):\n",
        "   {', '.join(candidate_row['matching_skills']) if candidate_row['matching_skills'] else 'None'}\n",
        "\n",
        "âŒ MISSING SKILLS ({len(candidate_row['missing_skills'])}):\n",
        "   {', '.join(candidate_row['missing_skills']) if candidate_row['missing_skills'] else 'None'}\n",
        "\n",
        "ðŸ’¡ RECOMMENDATION:\n",
        "   {'STRONG MATCH - Interview recommended' if candidate_row['final_score'] >= 50\n",
        "    else 'GOOD MATCH - Consider for interview' if candidate_row['final_score'] >= 35\n",
        "    else 'PARTIAL MATCH - May need training' if candidate_row['final_score'] >= 20\n",
        "    else 'WEAK MATCH - Not recommended'}\n",
        "\n",
        "ðŸ“ KEY INSIGHT:\n",
        "   {f\"Candidate has {len(candidate_row['matching_skills'])}/{total_required_skills} required skills. \" +\n",
        "    (f\"Strong in: {', '.join(candidate_row['matching_skills'][:3])}\" if len(candidate_row['matching_skills']) > 0 else \"Limited relevant experience\") +\n",
        "    (f\". Needs development in: {', '.join(candidate_row['missing_skills'][:3])}\" if len(candidate_row['missing_skills']) > 0 else \"\")}\n",
        "\n",
        "--------------------------------------------------------\n",
        "    \"\"\"\n",
        "    return explanation\n",
        "\n",
        "# Show detailed explanations for top 3\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DETAILED CANDIDATE EXPLANATIONS (FOR HR/MANAGERS)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i, (idx, row) in enumerate(top_candidates.head(3).iterrows(), 1):\n",
        "    print(explain_candidate_ranking(row, i, len(required_skills)))\n",
        "\n",
        "# Create summary table\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RANKING SUMMARY TABLE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "summary = top_candidates.head(10)[['Category', 'final_score', 'skill_match_pct']].copy()\n",
        "summary.columns = ['Job Category', 'Overall Match %', 'Skills Match %']\n",
        "summary['Rank'] = range(1, len(summary) + 1)\n",
        "summary = summary[['Rank', 'Job Category', 'Overall Match %', 'Skills Match %']]\n",
        "\n",
        "print(summary.to_string(index=False))\n",
        "\n",
        "print(f\"\\nâœ“ Step 5 Complete: Rankings explained clearly for non-technical users\")"
      ],
      "metadata": {
        "id": "dQSzU6j09z4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"SAVING MODELS FOR DEPLOYMENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save the vectorizer\n",
        "joblib.dump(vectorizer, 'resume_vectorizer.pkl')\n",
        "print(\"âœ“ Vectorizer saved\")\n",
        "\n",
        "# Save resume vectors\n",
        "joblib.dump(resume_vectors, 'resume_vectors.pkl')\n",
        "print(\"âœ“ Resume vectors saved\")\n",
        "\n",
        "# Save the processed dataframe (with cleaned text and skills)\n",
        "df.to_csv('processed_resumes.csv', index=False)\n",
        "print(\"âœ“ Processed resumes saved\")\n",
        "\n",
        "# Save skills database\n",
        "joblib.dump(SKILLS_DATABASE, 'skills_database.pkl')\n",
        "print(\"âœ“ Skills database saved\")\n",
        "\n",
        "# Save all skills list\n",
        "joblib.dump(all_skills, 'all_skills.pkl')\n",
        "print(\"âœ“ All skills list saved\")\n",
        "\n",
        "\n",
        "print(\"\\nFiles created:\")\n",
        "print(\"1. resume_vectorizer.pkl\")\n",
        "print(\"2. resume_vectors.pkl\")\n",
        "print(\"3. processed_resumes.csv\")\n",
        "print(\"4. skills_database.pkl\")\n",
        "print(\"5. all_skills.pkl\")\n",
        "\n",
        "# Download if in Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('resume_vectorizer.pkl')\n",
        "    files.download('resume_vectors.pkl')\n",
        "    files.download('processed_resumes.csv')\n",
        "    files.download('skills_database.pkl')\n",
        "    files.download('all_skills.pkl')\n",
        "    print(\"\\nâœ“ Files downloaded!\")\n",
        "except:\n",
        "    print(\"\\nâœ“ Files saved locally!\")"
      ],
      "metadata": {
        "id": "Z6TNSddKqt5t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}